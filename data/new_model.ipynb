{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before splitting:\n",
      "Acting: 2\n",
      "Adventure: 14\n",
      "Advocacy: 1\n",
      "Agility: 1\n",
      "Analytical skills: 7\n",
      "Animal care: 1\n",
      "Animation: 1\n",
      "Archaeology: 1\n",
      "Art therapy: 1\n",
      "Artistic: 7\n",
      "Artistic design: 1\n",
      "Artistic expression: 62\n",
      "Artistic skills: 5\n",
      "Astronomy: 1\n",
      "Athletic training: 1\n",
      "Attention to detail: 2\n",
      "Baking: 1\n",
      "Board games: 1\n",
      "Book clubs: 1\n",
      "Challenge: 6\n",
      "Challenges: 1\n",
      "Cognitive: 3\n",
      "Cognitive skills: 12\n",
      "Collaboration: 21\n",
      "Communication: 17\n",
      "Community: 45\n",
      "Community engagement: 1\n",
      "Community involvement: 1\n",
      "Community outreach: 1\n",
      "Community service: 14\n",
      "Compassion: 10\n",
      "Competition: 14\n",
      "Connection with animals: 6\n",
      "Content creation: 1\n",
      "Cooking: 6\n",
      "Cooking classes: 1\n",
      "Cooperative games: 1\n",
      "Coordination: 1\n",
      "Costume design: 1\n",
      "Crafting: 17\n",
      "Craftsmanship: 16\n",
      "Creative: 2\n",
      "Creative cooking: 1\n",
      "Creative problem-solving: 1\n",
      "Creative projects: 1\n",
      "Creative writing: 6\n",
      "Creativity: 104\n",
      "Critical thinking: 6\n",
      "Culinary adventure: 5\n",
      "Culinary arts: 11\n",
      "Culinary challenges: 1\n",
      "Culinary skills: 2\n",
      "Culinary techniques: 1\n",
      "Cultural appreciation: 8\n",
      "Cultural exploration: 3\n",
      "Cultural heritage: 1\n",
      "Cultural learning: 1\n",
      "Cultural storytelling: 1\n",
      "Cultural traditions: 1\n",
      "DIY: 18\n",
      "Dance: 2\n",
      "Digital: 2\n",
      "Digital art: 2\n",
      "Digital creativity: 4\n",
      "Digital marketing: 1\n",
      "Digital media: 4\n",
      "Digital skills: 3\n",
      "Digital storytelling: 1\n",
      "Drawing: 2\n",
      "Education: 21\n",
      "Electronics: 1\n",
      "Endurance: 4\n",
      "Environmental issues: 1\n",
      "Environmental stewardship: 13\n",
      "Experiential learning: 2\n",
      "Exploration: 35\n",
      "Expression: 1\n",
      "Expressive movement: 1\n",
      "Farming: 1\n",
      "Fashion design: 1\n",
      "Film: 1\n",
      "Financial literacy: 2\n",
      "Fishing: 1\n",
      "Fitness: 3\n",
      "Focus: 2\n",
      "Food exploration: 1\n",
      "Friendly competition: 1\n",
      "Furniture design: 1\n",
      "Game-based: 1\n",
      "Gardening: 3\n",
      "Global cuisines: 2\n",
      "Graphic design: 1\n",
      "Graphic novels: 1\n",
      "Group activities: 1\n",
      "Group art projects: 1\n",
      "Handmade skincare: 1\n",
      "Hands-on skills: 23\n",
      "Health: 1\n",
      "Healthy living: 1\n",
      "Historical appreciation: 7\n",
      "Historical architecture: 1\n",
      "Historical gardening: 1\n",
      "Historical interpretation: 1\n",
      "Historical reenactments: 1\n",
      "Hobbies: 1\n",
      "Holistic health: 1\n",
      "Home renovation: 1\n",
      "Hospitality: 3\n",
      "Improv theater: 1\n",
      "Individual sport: 4\n",
      "Individuality: 1\n",
      "Innovation: 13\n",
      "Innovative cooking: 1\n",
      "Introspection: 2\n",
      "Investment: 2\n",
      "Jewelry making: 1\n",
      "Journaling: 1\n",
      "Leadership: 4\n",
      "Learning: 2\n",
      "Literature: 3\n",
      "Meditation: 4\n",
      "Memoir writing: 1\n",
      "Memory preservation: 2\n",
      "Mental health: 1\n",
      "Mental wellness: 3\n",
      "Mindfulness: 33\n",
      "Mixed-media art: 1\n",
      "Music: 2\n",
      "Musical genres: 1\n",
      "Musical skills: 4\n",
      "Narrative design: 1\n",
      "Nature: 7\n",
      "Nature appreciation: 21\n",
      "Nature trips: 1\n",
      "Nature-oriented: 2\n",
      "Networking: 1\n",
      "Nurturing: 5\n",
      "Observation: 3\n",
      "Observational skills: 2\n",
      "Outdoor activities: 1\n",
      "Outdoor activity: 19\n",
      "Outdoor adventure: 1\n",
      "Outdoor adventures: 1\n",
      "Outdoor exploration: 1\n",
      "Outdoor fitness: 1\n",
      "Outdoor photography: 1\n",
      "Outdoor rock climbing: 1\n",
      "Painting: 3\n",
      "Patience: 4\n",
      "Performance: 20\n",
      "Personal expression: 1\n",
      "Personal growth: 19\n",
      "Personal storytelling: 1\n",
      "Personalized gifts: 1\n",
      "Pet care: 1\n",
      "Photography: 5\n",
      "Physical fitness: 37\n",
      "Planning: 1\n",
      "Podcasting: 1\n",
      "Poetry: 2\n",
      "Pottery: 1\n",
      "Practical skills: 2\n",
      "Precision: 1\n",
      "Problem-solving: 10\n",
      "Project management: 2\n",
      "Public relations: 1\n",
      "Public speaking: 2\n",
      "Puzzles: 1\n",
      "Quilting: 1\n",
      "Recreation: 30\n",
      "Recreational: 6\n",
      "Recreational activities: 1\n",
      "Relaxation: 12\n",
      "Research: 1\n",
      "Resilience: 1\n",
      "Responsibility: 1\n",
      "Scientific inquiry: 1\n",
      "Sculpture: 1\n",
      "Self-care: 1\n",
      "Self-discipline: 2\n",
      "Self-discovery: 2\n",
      "Self-expression: 15\n",
      "Self-reflection: 7\n",
      "Shared experiences: 1\n",
      "Short stories: 1\n",
      "Sketching: 1\n",
      "Skill development: 1\n",
      "Social: 6\n",
      "Social impact: 10\n",
      "Social interaction: 32\n",
      "Social media: 1\n",
      "Social support: 1\n",
      "Socializing: 1\n",
      "Songwriting: 1\n",
      "Sports: 5\n",
      "Sports coaching: 1\n",
      "Stargazing: 1\n",
      "Storytelling: 11\n",
      "Strategic thinking: 7\n",
      "Strategy: 4\n",
      "Support: 1\n",
      "Support for local artists: 1\n",
      "Survival skills: 2\n",
      "Sustainability: 4\n",
      "Tactile arts: 2\n",
      "Team collaboration: 1\n",
      "Teamwork: 17\n",
      "Technical skills: 6\n",
      "Technological skills: 7\n",
      "Technology: 5\n",
      "Textile arts: 2\n",
      "Textiles: 1\n",
      "Theatrical arts: 1\n",
      "Traditional arts: 2\n",
      "Training: 1\n",
      "Tranquility: 2\n",
      "Travel: 3\n",
      "Travel writing: 1\n",
      "Video creation: 1\n",
      "Video games: 1\n",
      "Visual art: 1\n",
      "Visual arts: 8\n",
      "Volunteer work: 1\n",
      "Wellness: 17\n",
      "Wilderness: 2\n",
      "Wildlife: 1\n",
      "Wildlife education: 1\n",
      "Wildlife volunteer work: 1\n",
      "Winter sports: 1\n",
      "Woodworking: 2\n",
      "Workshops: 1\n",
      "Writing: 13\n",
      "Yoga: 1\n",
      "Youth mentoring: 1\n",
      "outdoor activities: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marcin\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Marcin\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54aea4d43b9f45679db3beace292c0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a462225ea546009c234a00556f243a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7418.646484375, 'eval_runtime': 0.4014, 'eval_samples_per_second': 112.119, 'eval_steps_per_second': 14.949, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a171892241b4dd0b90e6418fd45b6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8920109272003174, 'eval_runtime': 0.4052, 'eval_samples_per_second': 111.069, 'eval_steps_per_second': 14.809, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c1134284c64e9fb2bc4f9e584eaba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.412678599357605, 'eval_runtime': 0.4352, 'eval_samples_per_second': 103.389, 'eval_steps_per_second': 13.785, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ce2e496b0e465695d1ee753d9e5624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10461199283599854, 'eval_runtime': 0.4285, 'eval_samples_per_second': 105.009, 'eval_steps_per_second': 14.001, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f3ba56d4014c06a8bae19c4ce0a1ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0842367634177208, 'eval_runtime': 0.4371, 'eval_samples_per_second': 102.959, 'eval_steps_per_second': 13.728, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d43421fb8f4965825bfc2f4cd6954a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0805240198969841, 'eval_runtime': 0.4215, 'eval_samples_per_second': 106.754, 'eval_steps_per_second': 14.234, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341d5736e9bf4cd2b67595ff21cf5df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07935456931591034, 'eval_runtime': 0.4044, 'eval_samples_per_second': 111.289, 'eval_steps_per_second': 14.839, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d162e8d9d00459a83031ecdf92c2c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07871467620134354, 'eval_runtime': 0.4508, 'eval_samples_per_second': 99.824, 'eval_steps_per_second': 13.31, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b69262525e46f384fd778f367f7183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07831087708473206, 'eval_runtime': 0.4978, 'eval_samples_per_second': 90.397, 'eval_steps_per_second': 12.053, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c595e111d34f728095e86cf33d5ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07821638882160187, 'eval_runtime': 0.5483, 'eval_samples_per_second': 82.069, 'eval_steps_per_second': 10.943, 'epoch': 10.0}\n",
      "{'train_runtime': 91.3496, 'train_samples_per_second': 22.989, 'train_steps_per_second': 2.956, 'train_loss': 123525.04444444444, 'epoch': 10.0}\n",
      "Label: Creativity, Probability: 0.2489\n",
      "Label: Artistic expression, Probability: 0.1651\n",
      "Label: Collaboration, Probability: 0.1371\n",
      "Label: Community, Probability: 0.1272\n",
      "Label: Recreation, Probability: 0.1150\n",
      "Label: Hands-on skills, Probability: 0.0999\n",
      "Label: Physical fitness, Probability: 0.0900\n",
      "Label: Mindfulness, Probability: 0.0687\n",
      "Label: Outdoor activity, Probability: 0.0681\n",
      "Label: Storytelling, Probability: 0.0635\n",
      "Label: Exploration, Probability: 0.0625\n",
      "Label: Nature appreciation, Probability: 0.0549\n",
      "Label: Communication, Probability: 0.0540\n",
      "Label: DIY, Probability: 0.0501\n",
      "Label: Personal growth, Probability: 0.0500\n",
      "Label: Teamwork, Probability: 0.0458\n",
      "Label: Social interaction, Probability: 0.0447\n",
      "Label: Performance, Probability: 0.0444\n",
      "Label: Relaxation, Probability: 0.0440\n",
      "Label: Education, Probability: 0.0425\n",
      "Label: Crafting, Probability: 0.0424\n",
      "Label: Wellness, Probability: 0.0424\n",
      "Label: Recreational, Probability: 0.0363\n",
      "Label: Competition, Probability: 0.0360\n",
      "Label: Writing, Probability: 0.0343\n",
      "Label: Culinary arts, Probability: 0.0332\n",
      "Label: Cognitive skills, Probability: 0.0293\n",
      "Label: Community service, Probability: 0.0286\n",
      "Label: Social, Probability: 0.0283\n",
      "Label: Craftsmanship, Probability: 0.0269\n",
      "Label: Self-expression, Probability: 0.0269\n",
      "Label: Innovation, Probability: 0.0266\n",
      "Label: Cooking classes, Probability: 0.0258\n",
      "Label: Cultural appreciation, Probability: 0.0249\n",
      "Label: Analytical skills, Probability: 0.0247\n",
      "Label: Adventure, Probability: 0.0246\n",
      "Label: Technological skills, Probability: 0.0243\n",
      "Label: Technology, Probability: 0.0234\n",
      "Label: Social impact, Probability: 0.0227\n",
      "Label: Strategic thinking, Probability: 0.0208\n",
      "Label: Literature, Probability: 0.0207\n",
      "Label: Self-discipline, Probability: 0.0205\n",
      "Label: Mental wellness, Probability: 0.0197\n",
      "Label: Historical appreciation, Probability: 0.0186\n",
      "Label: Nature, Probability: 0.0181\n",
      "Label: Wilderness, Probability: 0.0179\n",
      "Label: Self-reflection, Probability: 0.0164\n",
      "Label: Nature-oriented, Probability: 0.0151\n",
      "Label: Compassion, Probability: 0.0149\n",
      "Label: Problem-solving, Probability: 0.0148\n",
      "Label: Observation, Probability: 0.0143\n",
      "Label: Animal care, Probability: 0.0138\n",
      "Label: Creative problem-solving, Probability: 0.0133\n",
      "Label: Digital media, Probability: 0.0129\n",
      "Label: Strategy, Probability: 0.0128\n",
      "Label: Group art projects, Probability: 0.0127\n",
      "Label: Outdoor photography, Probability: 0.0120\n",
      "Label: Project management, Probability: 0.0119\n",
      "Label: Critical thinking, Probability: 0.0118\n",
      "Label: Introspection, Probability: 0.0116\n",
      "Label: Healthy living, Probability: 0.0113\n",
      "Label: Digital marketing, Probability: 0.0113\n",
      "Label: Musical skills, Probability: 0.0112\n",
      "Label: Cognitive, Probability: 0.0109\n",
      "Label: Cultural storytelling, Probability: 0.0109\n",
      "Label: Historical interpretation, Probability: 0.0104\n",
      "Label: Gardening, Probability: 0.0103\n",
      "Label: Community outreach, Probability: 0.0102\n",
      "Label: Group activities, Probability: 0.0098\n",
      "Label: Community involvement, Probability: 0.0094\n",
      "Label: Woodworking, Probability: 0.0092\n",
      "Label: Wildlife, Probability: 0.0091\n",
      "Label: Travel, Probability: 0.0089\n",
      "Label: Recreational activities, Probability: 0.0084\n",
      "Label: Endurance, Probability: 0.0083\n",
      "Label: Digital art, Probability: 0.0082\n",
      "Label: Individuality, Probability: 0.0082\n",
      "Label: Sports coaching, Probability: 0.0081\n",
      "Label: Artistic skills, Probability: 0.0080\n",
      "Label: Painting, Probability: 0.0079\n",
      "Label: Cultural exploration, Probability: 0.0076\n",
      "Label: Creative projects, Probability: 0.0074\n",
      "Label: Leadership, Probability: 0.0074\n",
      "Label: Artistic, Probability: 0.0073\n",
      "Label: Social media, Probability: 0.0071\n",
      "Label: Stargazing, Probability: 0.0071\n",
      "Label: Culinary skills, Probability: 0.0071\n",
      "Label: Sports, Probability: 0.0068\n",
      "Label: Furniture design, Probability: 0.0067\n",
      "Label: Music, Probability: 0.0067\n",
      "Label: Individual sport, Probability: 0.0065\n",
      "Label: Coordination, Probability: 0.0065\n",
      "Label: Sculpture, Probability: 0.0065\n",
      "Label: Podcasting, Probability: 0.0065\n",
      "Label: Artistic design, Probability: 0.0064\n",
      "Label: Environmental issues, Probability: 0.0062\n",
      "Label: Sketching, Probability: 0.0062\n",
      "Label: Investment, Probability: 0.0061\n",
      "Label: Digital creativity, Probability: 0.0060\n",
      "Label: Puzzles, Probability: 0.0059\n",
      "Label: Fitness, Probability: 0.0059\n",
      "Label: Outdoor activities, Probability: 0.0059\n",
      "Label: Historical reenactments, Probability: 0.0057\n",
      "Label: Animation, Probability: 0.0056\n",
      "Label: Friendly competition, Probability: 0.0056\n",
      "Label: Drawing, Probability: 0.0056\n",
      "Label: Journaling, Probability: 0.0056\n",
      "Label: Nurturing, Probability: 0.0055\n",
      "Label: Historical gardening, Probability: 0.0055\n",
      "Label: Nature trips, Probability: 0.0054\n",
      "Label: Board games, Probability: 0.0054\n",
      "Label: Musical genres, Probability: 0.0053\n",
      "Label: Shared experiences, Probability: 0.0053\n",
      "Label: Outdoor adventure, Probability: 0.0053\n",
      "Label: Volunteer work, Probability: 0.0053\n",
      "Label: Outdoor adventures, Probability: 0.0051\n",
      "Label: Connection with animals, Probability: 0.0050\n",
      "Label: Digital storytelling, Probability: 0.0049\n",
      "Label: Focus, Probability: 0.0049\n",
      "Label: Outdoor exploration, Probability: 0.0048\n",
      "Label: Photography, Probability: 0.0048\n",
      "Label: Financial literacy, Probability: 0.0048\n",
      "Label: Skill development, Probability: 0.0047\n",
      "Label: Public speaking, Probability: 0.0047\n",
      "Label: Observational skills, Probability: 0.0046\n",
      "Label: Challenge, Probability: 0.0046\n",
      "Label: Creative, Probability: 0.0045\n",
      "Label: Narrative design, Probability: 0.0045\n",
      "Label: Workshops, Probability: 0.0045\n",
      "Label: Graphic novels, Probability: 0.0044\n",
      "Label: Graphic design, Probability: 0.0044\n",
      "Label: Historical architecture, Probability: 0.0043\n",
      "Label: Wildlife education, Probability: 0.0043\n",
      "Label: Video games, Probability: 0.0043\n",
      "Label: Cooking, Probability: 0.0042\n",
      "Label: Scientific inquiry, Probability: 0.0042\n",
      "Label: Outdoor rock climbing, Probability: 0.0041\n",
      "Label: Hobbies, Probability: 0.0041\n",
      "Label: Textiles, Probability: 0.0041\n",
      "Label: Community engagement, Probability: 0.0041\n",
      "Label: Challenges, Probability: 0.0040\n",
      "Label: Practical skills, Probability: 0.0040\n",
      "Label: Culinary adventure, Probability: 0.0039\n",
      "Label: Experiential learning, Probability: 0.0039\n",
      "Label: Traditional arts, Probability: 0.0039\n",
      "Label: Social support, Probability: 0.0039\n",
      "Label: Agility, Probability: 0.0038\n",
      "Label: Patience, Probability: 0.0038\n",
      "Label: Technical skills, Probability: 0.0038\n",
      "Label: Planning, Probability: 0.0038\n",
      "Label: Attention to detail, Probability: 0.0037\n",
      "Label: Improv theater, Probability: 0.0037\n",
      "Label: Self-discovery, Probability: 0.0036\n",
      "Label: Costume design, Probability: 0.0036\n",
      "Label: Wildlife volunteer work, Probability: 0.0035\n",
      "Label: Socializing, Probability: 0.0035\n",
      "Label: Research, Probability: 0.0034\n",
      "Label: Memory preservation, Probability: 0.0033\n",
      "Label: Culinary techniques, Probability: 0.0033\n",
      "Label: Athletic training, Probability: 0.0032\n",
      "Label: Pottery, Probability: 0.0031\n",
      "Label: Support for local artists, Probability: 0.0031\n",
      "Label: Networking, Probability: 0.0031\n",
      "Label: Memoir writing, Probability: 0.0030\n",
      "Label: Cultural learning, Probability: 0.0029\n",
      "Label: Short stories, Probability: 0.0028\n",
      "Label: Digital, Probability: 0.0028\n",
      "Label: Creative cooking, Probability: 0.0027\n",
      "Label: Travel writing, Probability: 0.0027\n",
      "Label: Mixed-media art, Probability: 0.0027\n",
      "Label: Cultural traditions, Probability: 0.0027\n",
      "Label: Advocacy, Probability: 0.0026\n",
      "Label: Content creation, Probability: 0.0026\n",
      "Label: Visual art, Probability: 0.0026\n",
      "Label: Personal expression, Probability: 0.0025\n",
      "Label: Resilience, Probability: 0.0024\n",
      "Label: Acting, Probability: 0.0023\n",
      "Label: Cultural heritage, Probability: 0.0023\n",
      "Label: Personalized gifts, Probability: 0.0023\n",
      "Label: Expressive movement, Probability: 0.0022\n",
      "Label: Fashion design, Probability: 0.0022\n",
      "Label: Tranquility, Probability: 0.0020\n",
      "Label: Training, Probability: 0.0020\n",
      "Label: Electronics, Probability: 0.0020\n",
      "Label: Cooperative games, Probability: 0.0019\n",
      "Label: Holistic health, Probability: 0.0019\n",
      "Label: Sustainability, Probability: 0.0018\n",
      "Label: Public relations, Probability: 0.0017\n",
      "Label: Youth mentoring, Probability: 0.0017\n",
      "Label: Archaeology, Probability: 0.0016\n",
      "Label: Yoga, Probability: 0.0016\n",
      "Label: Winter sports, Probability: 0.0016\n",
      "Label: Jewelry making, Probability: 0.0015\n",
      "Label: Film, Probability: 0.0015\n",
      "Label: Tactile arts, Probability: 0.0014\n",
      "Label: Global cuisines, Probability: 0.0013\n",
      "Label: Food exploration, Probability: 0.0013\n",
      "Label: Mental health, Probability: 0.0012\n",
      "Label: Health, Probability: 0.0012\n",
      "Label: Quilting, Probability: 0.0012\n",
      "Label: Hospitality, Probability: 0.0011\n",
      "Label: Expression, Probability: 0.0011\n",
      "Label: Self-care, Probability: 0.0010\n",
      "Label: Video creation, Probability: 0.0009\n",
      "Label: Book clubs, Probability: 0.0009\n",
      "Label: Home renovation, Probability: 0.0009\n",
      "Label: outdoor activities, Probability: 0.0008\n",
      "Label: Digital skills, Probability: 0.0008\n",
      "Label: Precision, Probability: 0.0007\n",
      "Label: Art therapy, Probability: 0.0007\n",
      "Label: Innovative cooking, Probability: 0.0006\n",
      "Label: Meditation, Probability: 0.0005\n",
      "Label: Learning, Probability: 0.0005\n",
      "Label: Environmental stewardship, Probability: 0.0005\n",
      "Label: Support, Probability: 0.0005\n",
      "Label: Handmade skincare, Probability: 0.0004\n",
      "Label: Responsibility, Probability: 0.0004\n",
      "Label: Poetry, Probability: 0.0004\n",
      "Label: Personal storytelling, Probability: 0.0004\n",
      "Label: Survival skills, Probability: 0.0004\n",
      "Label: Team collaboration, Probability: 0.0003\n",
      "Label: Textile arts, Probability: 0.0003\n",
      "Label: Game-based, Probability: 0.0003\n",
      "Label: Pet care, Probability: 0.0003\n",
      "Label: Creative writing, Probability: 0.0002\n",
      "Label: Fishing, Probability: 0.0002\n",
      "Label: Baking, Probability: 0.0002\n",
      "Label: Outdoor fitness, Probability: 0.0001\n",
      "Label: Theatrical arts, Probability: 0.0001\n",
      "Label: Visual arts, Probability: 0.0001\n",
      "Label: Dance, Probability: 0.0001\n",
      "Label: Farming, Probability: 0.0001\n",
      "Label: Astronomy, Probability: 0.0001\n",
      "Label: Culinary challenges, Probability: 0.0000\n",
      "Label: Songwriting, Probability: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import MobileBertTokenizer, MobileBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# 1. Load the data from CSV\n",
    "df = pd.read_csv('train.csv')  # Path to your training data file\n",
    "df['labels'] = df['labels'].apply(lambda x: x.split(\", \"))  # Convert labels to lists\n",
    "\n",
    "# 2. Create MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df['labels'])  # Transform labels to binary format\n",
    "\n",
    "# 3. Check the distribution of classes\n",
    "class_counts = y.sum(axis=0)  # Sum instances for each class\n",
    "print(\"Class distribution before splitting:\")\n",
    "for label, count in zip(mlb.classes_, class_counts):\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "# 4. Split the data into training, validation, and test sets (70% train, 15% val, 15% test)\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    df['text'].tolist(), \n",
    "    y, \n",
    "    test_size=0.3,  # 30% data for temporary split (validation and test)\n",
    "    random_state=42,  # Random state for reproducibility\n",
    ")\n",
    "\n",
    "# Split the temporary data into validation and test sets (50/50 split)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, \n",
    "    temp_labels, \n",
    "    test_size=0.5,  # 50% of the temp set for validation, 50% for test\n",
    "    random_state=42,  # Random state for reproducibility\n",
    ")\n",
    "\n",
    "# 5. Define a custom dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.FloatTensor(label)  # Use FloatTensor for multi-label binary classification\n",
    "        }\n",
    "\n",
    "# 6. Initialize the tokenizer\n",
    "tokenizer = MobileBertTokenizer.from_pretrained('google/mobilebert-uncased')\n",
    "\n",
    "# 7. Create the datasets\n",
    "train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = TextDataset(val_texts, val_labels, tokenizer)\n",
    "test_dataset = TextDataset(test_texts, test_labels, tokenizer)\n",
    "\n",
    "# 8. Load the MobileBERT model\n",
    "model = MobileBertForSequenceClassification.from_pretrained(\n",
    "    'google/mobilebert-uncased', \n",
    "    num_labels=len(mlb.classes_), \n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "# 9. Set up the Trainer and Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',  # Evaluate at the end of each epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,  # Provide validation dataset here\n",
    ")\n",
    "\n",
    "# 10. Train the Model\n",
    "trainer.train()\n",
    "\n",
    "# 11. Save the Model and Tokenizer\n",
    "model.save_pretrained('my_mobilebert_model')\n",
    "tokenizer.save_pretrained('my_mobilebert_model')\n",
    "\n",
    "# Save the MultiLabelBinarizer for encoding/decoding labels\n",
    "joblib.dump(mlb, 'mlb.joblib')\n",
    "\n",
    "# 12. Define the inference function\n",
    "def predict(texts, model):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'  # Check device availability\n",
    "    model.to(device)  # Move model to the correct device\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            inputs = tokenizer(text, truncation=True, padding=True, return_tensors='pt', max_length=128)\n",
    "            # Move inputs to the correct device\n",
    "            for key in inputs.keys():\n",
    "                inputs[key] = inputs[key].to(device)\n",
    "            \n",
    "            logits = model(**inputs).logits\n",
    "            probabilities = torch.sigmoid(logits).cpu().numpy().flatten()  # Move probabilities back to CPU for numpy\n",
    "            predictions.append(probabilities)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# 13. Test the inference\n",
    "test_texts = [\"Can you recommend a hobby that involves creativity and nature?\"]\n",
    "predictions = predict(test_texts, model)  # Pass the model as an argument\n",
    "\n",
    "# Pair labels with their probabilities\n",
    "label_prob_pairs = list(zip(mlb.classes_, predictions.flatten()))\n",
    "\n",
    "# Sort pairs by probability in descending order\n",
    "sorted_label_prob_pairs = sorted(label_prob_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display results\n",
    "for label, prob in sorted_label_prob_pairs:\n",
    "    print(f\"Label: {label}, Probability: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Creativity, Probability: 0.3711\n",
      "Label: Artistic expression, Probability: 0.2213\n",
      "Label: Community, Probability: 0.2102\n",
      "Label: DIY, Probability: 0.1128\n",
      "Label: Recreation, Probability: 0.1028\n",
      "Label: Hands-on skills, Probability: 0.0811\n",
      "Label: Collaboration, Probability: 0.0751\n",
      "Label: Social interaction, Probability: 0.0725\n",
      "Label: Exploration, Probability: 0.0711\n",
      "Label: Physical fitness, Probability: 0.0655\n",
      "Label: Performance, Probability: 0.0625\n",
      "Label: Communication, Probability: 0.0602\n",
      "Label: Outdoor activity, Probability: 0.0547\n",
      "Label: Relaxation, Probability: 0.0503\n",
      "Label: Competition, Probability: 0.0487\n",
      "Label: Nature appreciation, Probability: 0.0477\n",
      "Label: Education, Probability: 0.0473\n",
      "Label: Mindfulness, Probability: 0.0463\n",
      "Label: Community service, Probability: 0.0453\n",
      "Label: Teamwork, Probability: 0.0431\n",
      "Label: Personal growth, Probability: 0.0404\n",
      "Label: Crafting, Probability: 0.0392\n",
      "Label: Culinary arts, Probability: 0.0362\n",
      "Label: Craftsmanship, Probability: 0.0355\n",
      "Label: Wellness, Probability: 0.0347\n",
      "Label: Writing, Probability: 0.0344\n",
      "Label: Strategic thinking, Probability: 0.0316\n",
      "Label: Storytelling, Probability: 0.0312\n",
      "Label: Compassion, Probability: 0.0297\n",
      "Label: Cultural appreciation, Probability: 0.0282\n",
      "Label: Social impact, Probability: 0.0262\n",
      "Label: Analytical skills, Probability: 0.0261\n",
      "Label: Self-expression, Probability: 0.0247\n",
      "Label: Cognitive skills, Probability: 0.0243\n",
      "Label: Historical appreciation, Probability: 0.0238\n",
      "Label: Self-discipline, Probability: 0.0234\n",
      "Label: Community involvement, Probability: 0.0226\n",
      "Label: Recreational, Probability: 0.0225\n",
      "Label: Problem-solving, Probability: 0.0215\n",
      "Label: Innovation, Probability: 0.0209\n",
      "Label: Technological skills, Probability: 0.0180\n",
      "Label: Nature-oriented, Probability: 0.0176\n",
      "Label: Cognitive, Probability: 0.0175\n",
      "Label: Endurance, Probability: 0.0174\n",
      "Label: Wilderness, Probability: 0.0169\n",
      "Label: Cooking classes, Probability: 0.0163\n",
      "Label: Observation, Probability: 0.0163\n",
      "Label: Social, Probability: 0.0161\n",
      "Label: Group art projects, Probability: 0.0150\n",
      "Label: Digital media, Probability: 0.0149\n",
      "Label: Technology, Probability: 0.0147\n",
      "Label: Adventure, Probability: 0.0145\n",
      "Label: Challenge, Probability: 0.0140\n",
      "Label: Mental wellness, Probability: 0.0139\n",
      "Label: Sculpture, Probability: 0.0129\n",
      "Label: Artistic skills, Probability: 0.0115\n",
      "Label: Literature, Probability: 0.0115\n",
      "Label: Self-reflection, Probability: 0.0113\n",
      "Label: Coordination, Probability: 0.0110\n",
      "Label: Outdoor photography, Probability: 0.0108\n",
      "Label: Creative problem-solving, Probability: 0.0105\n",
      "Label: Critical thinking, Probability: 0.0105\n",
      "Label: Nature, Probability: 0.0102\n",
      "Label: Outdoor adventure, Probability: 0.0102\n",
      "Label: Drawing, Probability: 0.0101\n",
      "Label: Digital marketing, Probability: 0.0101\n",
      "Label: Animal care, Probability: 0.0101\n",
      "Label: Gardening, Probability: 0.0095\n",
      "Label: Community outreach, Probability: 0.0095\n",
      "Label: Artistic design, Probability: 0.0094\n",
      "Label: Healthy living, Probability: 0.0092\n",
      "Label: Music, Probability: 0.0091\n",
      "Label: Strategy, Probability: 0.0090\n",
      "Label: Painting, Probability: 0.0089\n",
      "Label: Recreational activities, Probability: 0.0088\n",
      "Label: Social media, Probability: 0.0087\n",
      "Label: Creative, Probability: 0.0087\n",
      "Label: Public speaking, Probability: 0.0085\n",
      "Label: Project management, Probability: 0.0084\n",
      "Label: Outdoor adventures, Probability: 0.0082\n",
      "Label: Sports coaching, Probability: 0.0082\n",
      "Label: Group activities, Probability: 0.0080\n",
      "Label: Historical interpretation, Probability: 0.0079\n",
      "Label: Creative projects, Probability: 0.0078\n",
      "Label: Nurturing, Probability: 0.0073\n",
      "Label: Photography, Probability: 0.0072\n",
      "Label: Cultural storytelling, Probability: 0.0072\n",
      "Label: Investment, Probability: 0.0071\n",
      "Label: Connection with animals, Probability: 0.0071\n",
      "Label: Digital art, Probability: 0.0070\n",
      "Label: Board games, Probability: 0.0070\n",
      "Label: Individuality, Probability: 0.0069\n",
      "Label: Cultural exploration, Probability: 0.0069\n",
      "Label: Podcasting, Probability: 0.0067\n",
      "Label: Cooking, Probability: 0.0067\n",
      "Label: Outdoor activities, Probability: 0.0067\n",
      "Label: Traditional arts, Probability: 0.0067\n",
      "Label: Historical reenactments, Probability: 0.0066\n",
      "Label: Leadership, Probability: 0.0064\n",
      "Label: Introspection, Probability: 0.0064\n",
      "Label: Musical skills, Probability: 0.0061\n",
      "Label: Wildlife, Probability: 0.0061\n",
      "Label: Sports, Probability: 0.0060\n",
      "Label: Artistic, Probability: 0.0059\n",
      "Label: Travel, Probability: 0.0056\n",
      "Label: Workshops, Probability: 0.0054\n",
      "Label: Skill development, Probability: 0.0053\n",
      "Label: Challenges, Probability: 0.0053\n",
      "Label: Environmental issues, Probability: 0.0052\n",
      "Label: Animation, Probability: 0.0051\n",
      "Label: Narrative design, Probability: 0.0050\n",
      "Label: Financial literacy, Probability: 0.0050\n",
      "Label: Culinary skills, Probability: 0.0049\n",
      "Label: Graphic novels, Probability: 0.0049\n",
      "Label: Wildlife education, Probability: 0.0048\n",
      "Label: Video games, Probability: 0.0048\n",
      "Label: Volunteer work, Probability: 0.0047\n",
      "Label: Community engagement, Probability: 0.0047\n",
      "Label: Historical gardening, Probability: 0.0046\n",
      "Label: Furniture design, Probability: 0.0045\n",
      "Label: Observational skills, Probability: 0.0045\n",
      "Label: Culinary adventure, Probability: 0.0045\n",
      "Label: Digital creativity, Probability: 0.0044\n",
      "Label: Nature trips, Probability: 0.0044\n",
      "Label: Outdoor exploration, Probability: 0.0044\n",
      "Label: Musical genres, Probability: 0.0044\n",
      "Label: Individual sport, Probability: 0.0043\n",
      "Label: Socializing, Probability: 0.0043\n",
      "Label: Agility, Probability: 0.0042\n",
      "Label: Wildlife volunteer work, Probability: 0.0042\n",
      "Label: Focus, Probability: 0.0041\n",
      "Label: Shared experiences, Probability: 0.0040\n",
      "Label: Outdoor rock climbing, Probability: 0.0040\n",
      "Label: Experiential learning, Probability: 0.0040\n",
      "Label: Textiles, Probability: 0.0040\n",
      "Label: Attention to detail, Probability: 0.0039\n",
      "Label: Cultural learning, Probability: 0.0039\n",
      "Label: Memoir writing, Probability: 0.0039\n",
      "Label: Patience, Probability: 0.0038\n",
      "Label: Digital storytelling, Probability: 0.0038\n",
      "Label: Journaling, Probability: 0.0038\n",
      "Label: Content creation, Probability: 0.0037\n",
      "Label: Memory preservation, Probability: 0.0037\n",
      "Label: Puzzles, Probability: 0.0037\n",
      "Label: Fitness, Probability: 0.0036\n",
      "Label: Stargazing, Probability: 0.0033\n",
      "Label: Hobbies, Probability: 0.0033\n",
      "Label: Costume design, Probability: 0.0033\n",
      "Label: Woodworking, Probability: 0.0032\n",
      "Label: Scientific inquiry, Probability: 0.0032\n",
      "Label: Mixed-media art, Probability: 0.0032\n",
      "Label: Sketching, Probability: 0.0031\n",
      "Label: Advocacy, Probability: 0.0031\n",
      "Label: Networking, Probability: 0.0031\n",
      "Label: Cultural heritage, Probability: 0.0031\n",
      "Label: Travel writing, Probability: 0.0031\n",
      "Label: Visual art, Probability: 0.0030\n",
      "Label: Friendly competition, Probability: 0.0030\n",
      "Label: Athletic training, Probability: 0.0029\n",
      "Label: Culinary techniques, Probability: 0.0027\n",
      "Label: Public relations, Probability: 0.0026\n",
      "Label: Holistic health, Probability: 0.0026\n",
      "Label: Research, Probability: 0.0026\n",
      "Label: Practical skills, Probability: 0.0025\n",
      "Label: Planning, Probability: 0.0025\n",
      "Label: Pottery, Probability: 0.0025\n",
      "Label: Personal expression, Probability: 0.0025\n",
      "Label: Self-discovery, Probability: 0.0025\n",
      "Label: Mental health, Probability: 0.0025\n",
      "Label: Cooperative games, Probability: 0.0025\n",
      "Label: Short stories, Probability: 0.0024\n",
      "Label: Historical architecture, Probability: 0.0022\n",
      "Label: Improv theater, Probability: 0.0022\n",
      "Label: Digital, Probability: 0.0022\n",
      "Label: Personalized gifts, Probability: 0.0022\n",
      "Label: Expressive movement, Probability: 0.0022\n",
      "Label: Social support, Probability: 0.0022\n",
      "Label: Technical skills, Probability: 0.0022\n",
      "Label: Tranquility, Probability: 0.0020\n",
      "Label: Graphic design, Probability: 0.0020\n",
      "Label: Resilience, Probability: 0.0018\n",
      "Label: Yoga, Probability: 0.0018\n",
      "Label: Support for local artists, Probability: 0.0018\n",
      "Label: Electronics, Probability: 0.0017\n",
      "Label: Creative cooking, Probability: 0.0017\n",
      "Label: Cultural traditions, Probability: 0.0017\n",
      "Label: Global cuisines, Probability: 0.0016\n",
      "Label: Winter sports, Probability: 0.0015\n",
      "Label: Acting, Probability: 0.0015\n",
      "Label: Training, Probability: 0.0014\n",
      "Label: Self-care, Probability: 0.0014\n",
      "Label: Jewelry making, Probability: 0.0013\n",
      "Label: Fashion design, Probability: 0.0013\n",
      "Label: Expression, Probability: 0.0012\n",
      "Label: Food exploration, Probability: 0.0011\n",
      "Label: Digital skills, Probability: 0.0011\n",
      "Label: Health, Probability: 0.0010\n",
      "Label: Hospitality, Probability: 0.0010\n",
      "Label: Film, Probability: 0.0010\n",
      "Label: Tactile arts, Probability: 0.0009\n",
      "Label: Youth mentoring, Probability: 0.0009\n",
      "Label: Sustainability, Probability: 0.0009\n",
      "Label: Home renovation, Probability: 0.0008\n",
      "Label: Book clubs, Probability: 0.0008\n",
      "Label: Archaeology, Probability: 0.0007\n",
      "Label: Quilting, Probability: 0.0007\n",
      "Label: Innovative cooking, Probability: 0.0007\n",
      "Label: Handmade skincare, Probability: 0.0007\n",
      "Label: Learning, Probability: 0.0006\n",
      "Label: outdoor activities, Probability: 0.0006\n",
      "Label: Video creation, Probability: 0.0006\n",
      "Label: Art therapy, Probability: 0.0005\n",
      "Label: Support, Probability: 0.0005\n",
      "Label: Meditation, Probability: 0.0005\n",
      "Label: Precision, Probability: 0.0005\n",
      "Label: Environmental stewardship, Probability: 0.0005\n",
      "Label: Personal storytelling, Probability: 0.0004\n",
      "Label: Survival skills, Probability: 0.0004\n",
      "Label: Team collaboration, Probability: 0.0004\n",
      "Label: Pet care, Probability: 0.0004\n",
      "Label: Poetry, Probability: 0.0003\n",
      "Label: Responsibility, Probability: 0.0003\n",
      "Label: Textile arts, Probability: 0.0002\n",
      "Label: Game-based, Probability: 0.0002\n",
      "Label: Creative writing, Probability: 0.0002\n",
      "Label: Fishing, Probability: 0.0002\n",
      "Label: Outdoor fitness, Probability: 0.0001\n",
      "Label: Visual arts, Probability: 0.0001\n",
      "Label: Baking, Probability: 0.0001\n",
      "Label: Theatrical arts, Probability: 0.0001\n",
      "Label: Astronomy, Probability: 0.0001\n",
      "Label: Dance, Probability: 0.0001\n",
      "Label: Farming, Probability: 0.0000\n",
      "Label: Culinary challenges, Probability: 0.0000\n",
      "Label: Songwriting, Probability: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# 12. Define the inference function\n",
    "def predict(texts, model):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'  # Check device availability\n",
    "    model.to(device)  # Move model to the correct device\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            inputs = tokenizer(text, truncation=True, padding=True, return_tensors='pt', max_length=128)\n",
    "            # Move inputs to the correct device\n",
    "            for key in inputs.keys():\n",
    "                inputs[key] = inputs[key].to(device)\n",
    "            \n",
    "            logits = model(**inputs).logits\n",
    "            probabilities = torch.sigmoid(logits).cpu().numpy().flatten()  # Move probabilities back to CPU for numpy\n",
    "            predictions.append(probabilities)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# 13. Test the inference\n",
    "test_texts = [\"Can you recommend a hobby that helps improving my agility and speed?\"]\n",
    "predictions = predict(test_texts, model)  # Pass the model as an argument\n",
    "\n",
    "# Pair labels with their probabilities\n",
    "label_prob_pairs = list(zip(mlb.classes_, predictions.flatten()))\n",
    "\n",
    "# Sort pairs by probability in descending order\n",
    "sorted_label_prob_pairs = sorted(label_prob_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display results\n",
    "for label, prob in sorted_label_prob_pairs:\n",
    "    print(f\"Label: {label}, Probability: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marcin\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mlb.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import DistilBertTokenizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('train.csv')  # Update this with your actual path\n",
    "texts = data['text'].tolist()\n",
    "labels = [label.split(',') for label in data['labels'].tolist()]\n",
    "\n",
    "# Multi-label binarization\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(labels)\n",
    "\n",
    "# Split the dataset into train, validation, and test sets (70% train, 15% val, 15% test)\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    texts, labels, test_size=0.3\n",
    ")\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts, temp_labels, test_size=0.5\n",
    ")\n",
    "\n",
    "# Tokenization for train, validation, and test sets\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors='pt')\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, return_tensors='pt')\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "# Custom Dataset Class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomDataset(train_encodings, train_labels)\n",
    "val_dataset = CustomDataset(val_encodings, val_labels)\n",
    "test_dataset = CustomDataset(test_encodings, test_labels)\n",
    "\n",
    "# Save the tokenized datasets and labels for use in the second cell if needed\n",
    "torch.save(train_dataset, 'train_dataset.pt')\n",
    "torch.save(val_dataset, 'val_dataset.pt')\n",
    "torch.save(test_dataset, 'test_dataset.pt')\n",
    "\n",
    "# Save the MultiLabelBinarizer for encoding/decoding labels\n",
    "import joblib\n",
    "joblib.dump(mlb, 'mlb.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import DistilBertTokenizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv('train.csv')\n",
    "input_texts = dataset['text'].tolist()\n",
    "input_labels = [label.split(',') for label in dataset['labels'].tolist()]\n",
    "\n",
    "label_binarizer = MultiLabelBinarizer()\n",
    "encoded_labels = label_binarizer.fit_transform(input_labels)\n",
    "\n",
    "train_texts, remaining_texts, train_labels, remaining_labels = train_test_split(\n",
    "    input_texts, encoded_labels, test_size=0.3\n",
    ")\n",
    "validation_texts, test_texts, validation_labels, test_labels = train_test_split(\n",
    "    remaining_texts, remaining_labels, test_size=0.5\n",
    ")\n",
    "\n",
    "text_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "train_data_encodings = text_tokenizer(train_texts, truncation=True, padding=True, return_tensors='pt')\n",
    "validation_data_encodings = text_tokenizer(validation_texts, truncation=True, padding=True, return_tensors='pt')\n",
    "test_data_encodings = text_tokenizer(test_texts, truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = {key: val[index] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[index]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "training_dataset = TextDataset(train_data_encodings, train_labels)\n",
    "validation_dataset = TextDataset(validation_data_encodings, validation_labels)\n",
    "testing_dataset = TextDataset(test_data_encodings, test_labels)\n",
    "\n",
    "torch.save(training_dataset, 'training_dataset.pt')\n",
    "torch.save(validation_dataset, 'validation_dataset.pt')\n",
    "torch.save(testing_dataset, 'testing_dataset.pt')\n",
    "\n",
    "import joblib\n",
    "joblib.dump(label_binarizer, 'label_binarizer.joblib')\n",
    "\n",
    "import torch\n",
    "from transformers import MobileBertForSequenceClassification, Trainer, TrainingArguments, MobileBertTokenizer\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "mobilebert_tokenizer = MobileBertTokenizer.from_pretrained('google/mobilebert-uncased')\n",
    "\n",
    "def calculate_metrics(predictions):\n",
    "    binary_preds = (predictions.predictions > 0.5).astype(int)\n",
    "    true_labels = predictions.label_ids\n",
    "\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(\n",
    "        true_labels, binary_preds, average='weighted', zero_division=0\n",
    "    )\n",
    "    accuracy = accuracy_score(true_labels, binary_preds)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1_score,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "    }\n",
    "\n",
    "loaded_training_dataset = torch.load('training_dataset.pt')\n",
    "loaded_validation_dataset = torch.load('validation_dataset.pt')\n",
    "loaded_testing_dataset = torch.load('testing_dataset.pt')\n",
    "\n",
    "classification_model = MobileBertForSequenceClassification.from_pretrained(\n",
    "    'google/mobilebert-uncased',\n",
    "    num_labels=len(loaded_training_dataset.labels[0]),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "training_config = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "model_trainer = Trainer(\n",
    "    model=classification_model,\n",
    "    args=training_config,\n",
    "    train_dataset=loaded_training_dataset,\n",
    "    eval_dataset=loaded_validation_dataset,\n",
    "    compute_metrics=calculate_metrics,\n",
    ")\n",
    "\n",
    "model_trainer.train()\n",
    "\n",
    "validation_results = model_trainer.evaluate()\n",
    "print(validation_results)\n",
    "\n",
    "validation_predictions = model_trainer.predict(loaded_validation_dataset)\n",
    "binary_predictions = (validation_predictions.predictions > 0.5).astype(int)\n",
    "true_validation_labels = validation_predictions.label_ids\n",
    "\n",
    "print(\"Predictions:\", binary_predictions)\n",
    "print(\"True Labels:\", true_validation_labels)\n",
    "\n",
    "test_results = model_trainer.evaluate(loaded_testing_dataset)\n",
    "print(test_results)\n",
    "\n",
    "classification_model.save_pretrained('fine_tuned_model')\n",
    "mobilebert_tokenizer.save_pretrained('fine_tuned_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
